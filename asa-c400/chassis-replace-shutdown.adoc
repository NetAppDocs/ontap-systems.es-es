---
permalink: asa-c400/chassis-replace-shutdown.html 
sidebar: sidebar 
keywords: asa c400, asa, c400, component, system, function, properly, contact, technical, support, replace, chassis, shut, down, controller, replacing, remove, module, fan, equipment, rack, cabinet, ha, state, switch, back, aggregate, two-node, metrocluster, configuration, complete, replacement, process, replace the chassis, shut down the controllers when replacing a chassis, remove the controller modules, move the fans, replace a chassis from within the equipment rack or system cabinet, install the controller modules, verify and set the ha state of the chassis, switch back aggregates in a two-node metrocluster configuration, complete the replacement process 
summary: Para sustituir el chasis, debe apagar las controladoras. 
---
= Apague los controladores - ASA C400
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Apague o retome el controlador dañado siguiendo el procedimiento adecuado para su configuración.



== Opción 1: Apague las controladoras al sustituir un chasis

Apague las controladoras para poder realizar el mantenimiento del chasis.

Este procedimiento es para sistemas con configuraciones de dos nodos. Si tiene un sistema con más de dos nodos, consulte https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/How_to_perform_a_graceful_shutdown_and_power_up_of_one_HA_pair_in_a_4__node_cluster["Cómo realizar un apagado y encendido con gracia de una pareja de alta disponibilidad en un clúster de cuatro nodos"^].

.Antes de empezar
* Detenga el acceso de todos los clientes/host a los datos del sistema de NetApp.
* Suspender trabajos de backup externo.
* Asegúrese de que dispone de los permisos y credenciales necesarios:
+
** Credenciales de administrador local para ONTAP.
** Clave de acceso para todo el clúster de gestión de claves incorporada de NetApp (OKM) si usa cifrado de almacenamiento o NVE/NAE.
** Accesibilidad de BMC para cada controladora.


* Asegúrese de que dispone de las herramientas y el equipo necesarios para la sustitución.
* Como práctica recomendada antes del cierre, debe:
+
** Realizar adicionales https://kb.netapp.com/onprem/ontap/os/How_to_perform_a_cluster_health_check_with_a_script_in_ONTAP["comprobaciones de estado del sistema"].
** Actualice ONTAP a una versión recomendada para el sistema.
** Resuelva cualquier https://activeiq.netapp.com/["Alertas de estado y riesgos de Active IQ"]. Tome nota de cualquier fallo presente en el sistema, como los LED de los componentes del sistema.




.Pasos
. Inicie sesión en el clúster a través de SSH o inicie sesión desde cualquier nodo del clúster mediante un cable de consola local y un equipo portátil/consola.
. Desactive AutoSupport e indique cuánto tiempo espera que el sistema esté fuera de línea:
+
`system node autosupport invoke -node * -type all -message "MAINT=8h Power Maintenance"`

. Identifique la dirección del SP/BMC de todos los nodos:
+
`system service-processor show -node * -fields address`

. Salga del shell de cluster: `exit`
. Inicie sesión en SP/BMC sobre SSH con la dirección IP de cualquiera de los nodos que aparecen en el resultado del paso anterior.
+
Si está utilizando una consola/portátil, inicie sesión en la controladora con las mismas credenciales de administrador del clúster.

+

NOTE: Abra una sesión SSH en cada conexión SP/BMC de modo que pueda supervisar el progreso.

. Detenga los dos nodos ubicados en el chasis dañado:
+
`system node halt -node <node>,<node2> -skip-lif-migration-before-shutdown true -ignore-quorum-warnings true -inhibit-takeover true`

+

NOTE: Para los clústeres que utilizan SnapMirror síncrono en modo StrictSync: `system node halt -node <node>,<node2>  -skip-lif-migration-before-shutdown true -ignore-quorum-warnings true -inhibit-takeover true -ignore-strict-sync-warnings true`

. Introduzca *y* para cada controlador en el clúster cuando lo vea `_Warning: Are you sure you want to halt node "cluster <node-name> number"?
{y|n}:_`
. Espere a que cada controladora se detenga y muestre el aviso del CARGADOR.




== Opción 2: Apague una controladora en una configuración MetroCluster de dos nodos

Para apagar el controlador dañado, debe determinar el estado del controlador y, si es necesario, cambiar el controlador para que el controlador correcto siga sirviendo datos del almacenamiento del controlador dañado.

.Acerca de esta tarea
* Debe dejar las fuentes de alimentación encendidas al final de este procedimiento para proporcionar alimentación a la controladora en buen estado.


.Pasos
. Compruebe el estado de MetroCluster para determinar si el controlador dañado ha cambiado automáticamente al controlador en buen estado: `metrocluster show`
. En función de si se ha producido una conmutación automática, proceda según la siguiente tabla:
+
[cols="1,2"]
|===
| Si el controlador está dañado... | Realice lo siguiente... 


 a| 
Se ha cambiado automáticamente
 a| 
Continúe con el próximo paso.



 a| 
No se ha cambiado automáticamente
 a| 
Realice una operación de conmutación de sitios planificada desde el controlador en buen estado: `metrocluster switchover`



 a| 
No se ha cambiado automáticamente, ha intentado efectuar una conmutación con el `metrocluster switchover` y se vetó la conmutación
 a| 
Revise los mensajes de veto y, si es posible, resuelva el problema e inténtelo de nuevo. Si no puede resolver el problema, póngase en contacto con el soporte técnico.

|===
. Resincronice los agregados de datos ejecutando el `metrocluster heal -phase aggregates` comando del clúster superviviente.
+
[listing]
----
controller_A_1::> metrocluster heal -phase aggregates
[Job 130] Job succeeded: Heal Aggregates is successful.
----
+
Si la curación es vetada, usted tiene la opción de reemitir el `metrocluster heal` con el `-override-vetoes` parámetro. Si utiliza este parámetro opcional, el sistema anula cualquier vetoo suave que impida la operación de reparación.

. Compruebe que se ha completado la operación con el comando MetroCluster operation show.
+
[listing]
----
controller_A_1::> metrocluster operation show
    Operation: heal-aggregates
      State: successful
Start Time: 7/25/2016 18:45:55
   End Time: 7/25/2016 18:45:56
     Errors: -
----
. Compruebe el estado de los agregados mediante `storage aggregate show` comando.
+
[listing]
----
controller_A_1::> storage aggregate show
Aggregate     Size Available Used% State   #Vols  Nodes            RAID Status
--------- -------- --------- ----- ------- ------ ---------------- ------------
...
aggr_b2    227.1GB   227.1GB    0% online       0 mcc1-a2          raid_dp, mirrored, normal...
----
. Repare los agregados raíz mediante el `metrocluster heal -phase root-aggregates` comando.
+
[listing]
----
mcc1A::> metrocluster heal -phase root-aggregates
[Job 137] Job succeeded: Heal Root Aggregates is successful
----
+
Si la curación es vetada, usted tiene la opción de reemitir el `metrocluster heal` comando con el parámetro -override-vetoes. Si utiliza este parámetro opcional, el sistema anula cualquier vetoo suave que impida la operación de reparación.

. Compruebe que la operación reparar se ha completado mediante el `metrocluster operation show` comando en el clúster de destino:
+
[listing]
----

mcc1A::> metrocluster operation show
  Operation: heal-root-aggregates
      State: successful
 Start Time: 7/29/2016 20:54:41
   End Time: 7/29/2016 20:54:42
     Errors: -
----
. En el módulo del controlador dañado, desconecte las fuentes de alimentación.

